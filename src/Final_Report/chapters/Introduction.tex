\chapter{Introduction}
\section{Overview}
Ever since computers were developed, scientists and engineers thought of artificially intelligent systems that are mentally and/or physically equivalent to humans. In the past decade, the increase of generally available computational power provided a helping hand for developing fast learning machines, whereas the Internet supplied an enormous amount of data for training.\\ 
These two developments boosted the research on smart self-learning systems, with neural networks among the most promising techniques.\\
In the last decade, the progress made by machine learning has been astounding, allowing it to grow in popularity both as a research field and as a basis for commercial applications.

Hard-coded rules and rigid behaviour have been replaced with algorithms capable of generalization, leading to recent developments in speech recognition, computer vision, natural language processing as well as computational finance and medical diagnosis.

Adaptive systems can be used to intelligently manage the affective dimension of the learner in order to foster the interplay that exists between the cognitive aspects of learning and affect

Emotions often mediate and facilitate interactions among human beings. Thus, understanding emotion often brings context to seemingly bizarre and/or complex social communication. Emotion can be recognized through a variety of means such as voice intonation, body language, and more complex methods such electroencephalography (EEG)

In our research,  we aim at integrating cognition with userâ€™s emotions to provide adaptive learning, where a multi-modal approach based on mining several input data sources. We present a deep learning based approach to modelling different input modalities and to combining them in order to infer emotion labels from a given video sequence. We mainly focus on neural network based artificially intelligent systems capable of deriving the emotion of a person through pictures of his or her face

Emotion analysis is particularly challenging as multiple input modalities, both visual and auditory, play an important role in understanding it. Given a video sequence with a human subject, some of the important cues which help to understand the users emotion are facial expressions, movements and activities.

Emotion recognition can be used for surveillance purposes by law enforcers as well as in crowd management. We are developing a software which can recognise the emotion of a person from its face or audio file. We can predict the behaviour of a person based on that whether he or she is happy or sad.\\
In total we are developing a model which can detect 7 emotions from that.

\section{Project Category}
This project can be classified as being an application development project. But as much as it is an application development project, it is also a research project. It took a fair share of observation and study in order to find the right approach the problem. The study involved learning about various classifiers based on Haar-like features, which is the most common technique in computer-vision for face and eye detection to constructs models used in the Neural network.
\\
All libraries used in this project are free and/or open-source.

\section{Objectives}
Artificial neural networks (ANNs) are machine learning models inspired by the animal brain in the hope that they can be used to reverse engineer how animals learn to perform certain tasks.

Even though ANNs are inspired by biological neural networks, they are far from being biologically realistic, as both the structure and the building blocks of ANNs are oversimplification of their counterparts found in nature.

We mainly focus on neural network based artificially intelligent systems capable of deriving the emotion of a person through pictures of his or her face. The main research question therefore reads as follows: How can an artificial neural network be used for interpreting the facial expression of a human? 