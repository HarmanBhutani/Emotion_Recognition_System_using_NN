\begin{center}
	{\Huge Introduction}
\end{center}

\section{Introduction}
Ever since computers were developed, scientists and engineers thought of artificially intelligent systems that that are mentally and/or physically equivalent to humans. In the past decades, the increase of generally available computational power provided a helping hand for developing fast learning machines, whereas the Internet supplied an enormous amount of data for training. These two developments boosted the research on smart self-learning systems, with neural networks among the most promising techniques.\newline

Human emotion analysis is a challenging machine learning task with a wide range of applications in human-computer interaction, e-learning, health care, advertising and gaming.\newline

Emotion analysis is particularly challenging as multiple input modalities, both visual and auditory, play an important role in understanding it. Given a video sequence with a human subject, some of the important cues which help to understand the userâ€™s emotion are facial expressions, movements and activities.\newline

Most of the time there is a considerable overlap between emotion classes making it a challenging classification task.\newline

In this paper we present a deep learning based approach to modeling different input modalities and to combining them in order to infer emotion labels from a given video sequence. We mainly focus on neural network based artificially intelligent systems capable of deriving the emotion of a person through pictures of his or her face\newline

We are developing a software which can recognise the emotion of  a person from its face or audio file. We can predict the behavior of a person based on that whether he or she is happy or sad. \newline 

In total we are developing a model which can detect 7 emotions from that.